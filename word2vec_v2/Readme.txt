	
1.Project 
 - Reproducing Vector Representations of Words

2.Description
 - Using skipgram model, autoencoder is implemented with layers of an encoder, embeddings and decoder. For visualization, not only do nearest words are generated with cosine similarity, but also t-distributed stochastic nearest embedding(tsne) are used.

3.Date & Author
 - Aug 2017, Gonsoo Moon

4.Environment
 1) Mac Pro 2.6 GHz Intel Core i5, 16 GB RAM
 2) Tensorflow 1.0.0
 3) Python 3.6

5.How to run
 On the command line, type the following
 python skipgram_v1.0.py 

6.Result
 - Refer to the project report

7.Reference
 [1] Nikhil Buduma (2017). Fundamentals of deep learning. Sebastopol, CA: Oâ€™Reilly Media

	   


	
