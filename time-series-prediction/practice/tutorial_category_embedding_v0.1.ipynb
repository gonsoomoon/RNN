{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using categorical data in machine learning with python<br></h1>\n",
    "https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data fields (https://www.kaggle.com/c/avazu-ctr-prediction/data)\n",
    "\n",
    "id: ad identifier\n",
    "click: 0/1 for non-click/click\n",
    "hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.\n",
    "C1 -- anonymized categorical variable\n",
    "banner_pos\n",
    "site_id\n",
    "site_domain\n",
    "site_category\n",
    "app_id\n",
    "app_domain\n",
    "app_category\n",
    "device_id\n",
    "device_ip\n",
    "device_model\n",
    "device_type\n",
    "device_conn_type\n",
    "C14-C21 -- anonymized categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000009418151094273</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000169349117863715</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000371904215119486</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000640724480838376</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000679056417042096</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18993</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  click      hour    C1  banner_pos   site_id  \\\n",
       "0   1000009418151094273      0  14102100  1005           0  1fbe01fe   \n",
       "1  10000169349117863715      0  14102100  1005           0  1fbe01fe   \n",
       "2  10000371904215119486      0  14102100  1005           0  1fbe01fe   \n",
       "3  10000640724480838376      0  14102100  1005           0  1fbe01fe   \n",
       "4  10000679056417042096      0  14102100  1005           1  fe8cc448   \n",
       "\n",
       "  site_domain site_category    app_id app_domain ...  device_type  \\\n",
       "0    f3845767      28905ebd  ecad2386   7801e8d9 ...            1   \n",
       "1    f3845767      28905ebd  ecad2386   7801e8d9 ...            1   \n",
       "2    f3845767      28905ebd  ecad2386   7801e8d9 ...            1   \n",
       "3    f3845767      28905ebd  ecad2386   7801e8d9 ...            1   \n",
       "4    9166c161      0569f928  ecad2386   7801e8d9 ...            1   \n",
       "\n",
       "  device_conn_type    C14  C15  C16   C17  C18  C19     C20  C21  \n",
       "0                2  15706  320   50  1722    0   35      -1   79  \n",
       "1                0  15704  320   50  1722    0   35  100084   79  \n",
       "2                0  15704  320   50  1722    0   35  100084   79  \n",
       "3                0  15706  320   50  1722    0   35  100084   79  \n",
       "4                0  18993  320   50  2161    0   35      -1  157  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.metrics import log_loss\n",
    "import copy\n",
    "\n",
    "train_file = \"../input/click_through/train_obs10000.csv\"\n",
    "train = pandas.read_csv(train_file)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msk shape:  (9999,) msk:  [ True  True  True ...  True  True  True]\n",
      "X_train shape:  (8056, 20)\n",
      "X_test shape:  (1943, 20)\n",
      "y_train shape:  (8056,)\n",
      "y_test shape:  (1943,)\n",
      "     C1  banner_pos   site_id site_domain site_category    app_id app_domain  \\\n",
      "0  1005           0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
      "1  1005           0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
      "\n",
      "  app_category device_id device_model  device_type  device_conn_type    C14  \\\n",
      "0     07d7df22  a99f214a     44956a24            1                 2  15706   \n",
      "1     07d7df22  a99f214a     711ee120            1                 0  15704   \n",
      "\n",
      "   C15  C16   C17  C18  C19     C20  C21  \n",
      "0  320   50  1722    0   35      -1   79  \n",
      "1  320   50  1722    0   35  100084   79  \n",
      "0    0\n",
      "1    0\n",
      "Name: click, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(len(train)) < 0.8\n",
    "print(\"msk shape: \", msk.shape, \"msk: \", msk)\n",
    "features = [3,4,5,6,7,8,9,10,11,13,14,15,16,17,18,19,20,21,22,23]\n",
    "X_train = train[msk].iloc[:, features]\n",
    "X_test = train[~msk].iloc[:, features]\n",
    "y_train = train[msk].iloc[:,1]\n",
    "y_test = train[~msk].iloc[:,1]\n",
    "\n",
    "X_train_ori = copy.deepcopy(X_train)\n",
    "X_test_ori = copy.deepcopy(X_test)\n",
    "y_train_ori = copy.deepcopy(y_train)\n",
    "y_test_ori = copy.deepcopy(y_test)\n",
    "\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print(X_train_ori.head(2))\n",
    "print(y_train_ori.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line:  0.47458841471057495\n"
     ]
    }
   ],
   "source": [
    "print(\"Base line: \", log_loss(y_test, np.ones(len(y_test)) * y_train.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Embedding Method 1: Encoding to ordinal variables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ordinal transform:  [2 2 2 ... 2 2 2]\n",
      "train ordinal transform:  [0 0 0 ... 0 1 0]\n",
      "train ordinal transform:  [ 43  43  43 ...  43 141 202]\n",
      "train ordinal transform:  [301 301 301 ... 301  27 244]\n",
      "train ordinal transform:  [ 2  2  2 ...  2 12  5]\n",
      "train ordinal transform:  [293 293 293 ... 293 293 119]\n",
      "train ordinal transform:  [13 13 13 ... 13 13  3]\n",
      "train ordinal transform:  [0 0 0 ... 0 0 2]\n",
      "train ordinal transform:  [722 722 722 ... 722 722 722]\n",
      "train ordinal transform:  [315 488 604 ... 987 992 204]\n",
      "train ordinal transform:  [1 1 1 ... 1 1 1]\n",
      "train ordinal transform:  [1 0 0 ... 0 0 0]\n",
      "train ordinal transform:  [ 67  65  65 ...  62  87 241]\n",
      "train ordinal transform:  [2 2 2 ... 2 2 2]\n",
      "train ordinal transform:  [1 1 1 ... 1 1 1]\n",
      "train ordinal transform:  [ 27  27  27 ...  27  40 104]\n",
      "train ordinal transform:  [0 0 0 ... 0 0 3]\n",
      "train ordinal transform:  [ 0  0  0 ...  0 16 12]\n",
      "train ordinal transform:  [ 0 42 42 ...  0  0 55]\n",
      "train ordinal transform:  [15 15 15 ... 15 26 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_ordinal = X_train.values\n",
    "X_test_ordinal = X_test.values\n",
    "les = []\n",
    "l = LogisticRegression()\n",
    "r = RandomForestClassifier(n_estimators=25, max_depth=10)\n",
    "for i in  range(X_train_ordinal.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train.iloc[:, features].iloc[:, i])\n",
    "    les.append(le)\n",
    "    train_ordinal_embedding = le.transform(X_train_ordinal[:,i])\n",
    "    X_train_ordinal[:, i] = train_ordinal_embedding\n",
    "    print(\"train ordinal transform: \", train_ordinal_embedding)\n",
    "    X_test_ordinal[:,i] = le.transform(X_test_ordinal[:,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.4542862899520212\n",
      "Random Forest:  0.434011278356416\n"
     ]
    }
   ],
   "source": [
    "l.fit(X_train_ordinal, y_train)\n",
    "y_pred = l.predict_proba(X_test_ordinal)\n",
    "print(\"Logistic Regression: \", log_loss(y_test, y_pred))\n",
    "r.fit(X_train_ordinal, y_train)\n",
    "y_pred = r.predict_proba(X_test_ordinal)\n",
    "print(\"Random Forest: \", log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where in logistic regression we apply a coefficient to each explaining featuer (most of which contain merely noise, dueo to the nonsense encoding), random noise includes an inherent feature selection mechanism. Most probably, random forest selected these features in which the encoding somehow correlated with the CTR, and used mainly these features to explain the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Method 2: One hot encoding (or dummy variables)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.4333707765043064\n",
      "RF:  0.44193633413557315\n",
      "(8056, 3446)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train_ordinal)\n",
    "X_train_one_hot = enc.transform(X_train_ordinal)\n",
    "X_test_one_hot = enc.transform(X_test_ordinal)\n",
    "l.fit(X_train_one_hot, y_train)\n",
    "y_pred = l.predict_proba(X_test_one_hot)\n",
    "print(\"LR: \", log_loss(y_test, y_pred))\n",
    "r.fit(X_train_one_hot, y_train)\n",
    "y_pred = r.predict_proba(X_test_one_hot)\n",
    "print(\"RF: \", log_loss(y_test, y_pred))\n",
    "print(X_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why is logistic regression better than random forest? In this method we represented our data with a huge amount of features (curse of dimensionality). Having many features we need a very simple classifier in order to not overfit the data. Logistic regression is way more simple than random forest. Moreover, the sparsity of the data makes it very hard for the random forest to find good splits that will help in separating the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reduce dimenstions with being rare</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.4305982457848496\n",
      "RF:  0.43399603103418616\n",
      "(8056, 422)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "X_train_rare = copy.copy(X_train)\n",
    "X_test_rare = copy.copy(X_test)\n",
    "X_train_rare[\"test\"]=0\n",
    "X_test_rare[\"test\"]=1\n",
    "temp_df = pandas.concat([X_train_rare,X_test_rare],axis=0)\n",
    "names = list(X_train_rare.columns.values)\n",
    "temp_df = pandas.concat([X_train_rare,X_test_rare],axis=0)\n",
    "for i in names:\n",
    "    temp_df.loc[temp_df[i].value_counts()[temp_df[i]].values < 20, i] = \"RARE_VALUE\"\n",
    "for i in range(temp_df.shape[1]):\n",
    "    temp_df.iloc[:,i]=temp_df.iloc[:,i].astype('str')\n",
    "    \n",
    "X_train_rare = temp_df[temp_df[\"test\"]==\"0\"].iloc[:,:-1].values\n",
    "X_test_rare = temp_df[temp_df[\"test\"]==\"1\"].iloc[:,:-1].values\n",
    "for i in range(X_train_rare.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(temp_df.iloc[:,:-1].iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_rare[:, i] = le.transform(X_train_rare[:, i])\n",
    "    X_test_rare[:, i] = le.transform(X_test_rare[:, i])\n",
    "    \n",
    "enc.fit(X_train_rare)\n",
    "X_train_rare = enc.transform(X_train_rare)\n",
    "X_test_rare = enc.transform(X_test_rare)\n",
    "l.fit(X_train_rare,y_train)\n",
    "y_pred = l.predict_proba(X_test_rare)\n",
    "print(\"LR: \", log_loss(y_test,y_pred))\n",
    "r.fit(X_train_rare,y_train)\n",
    "y_pred = r.predict_proba(X_test_rare)\n",
    "print(\"RF: \", log_loss(y_test,y_pred))\n",
    "print(X_train_rare.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can overcome some of this disadvantages by encoding all rare categories to the same features (“rare value”). This method can reduce the dimensionality drastically in some datasets with a small decrease in performance (or even an increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Method 3: Feature hashing (a.k.a the hashing trick)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hash:  (8056, 21)\n",
      "X_test_hash:  (1943, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "X_train_hash = copy.copy(X_train)\n",
    "X_test_hash = copy.copy(X_test)\n",
    "print(\"X_train_hash: \", X_train_hash.shape)\n",
    "print(\"X_test_hash: \", X_test_hash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to an object type using \"str\"\n",
    "for i in range(X_train_hash.shape[1]):\n",
    "    X_train_hash.iloc[:,i] = X_train_hash.iloc[:,i].astype('str')\n",
    "for i in range(X_test_hash.shape[1]):\n",
    "    X_test_hash.iloc[:,i] = X_test_hash.iloc[:,i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1005' '0' '1fbe01fe' 'f3845767' '28905ebd' 'ecad2386' '7801e8d9'\n",
      " '07d7df22' 'a99f214a' '44956a24' '1' '2' '15706' '320' '50' '1722' '0'\n",
      " '35' '-1' '79' '0']\n",
      "     C1 banner_pos   site_id site_domain site_category    app_id app_domain  \\\n",
      "6  1005          0  8fda644b    25d4cfcd      f028772b  ecad2386   7801e8d9   \n",
      "\n",
      "  app_category device_id device_model ...  device_conn_type    C14  C15 C16  \\\n",
      "6     07d7df22  a99f214a     be6db1d7 ...                 0  20362  320  50   \n",
      "\n",
      "    C17 C18 C19 C20  C21 test  \n",
      "6  2333   0  39  -1  157    1  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_hash.values[0])\n",
    "print(X_test_hash.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = FeatureHasher(n_features=100, input_type=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_hash = h.transform(X_train_hash.values)\n",
    "X_test_hash = h.transform(X_test_hash.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8056, 100)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 0)\t0.0\n",
      "  (0, 2)\t-1.0\n",
      "  (0, 7)\t2.0\n",
      "  (0, 28)\t-1.0\n",
      "  (0, 35)\t1.0\n",
      "  (0, 37)\t3.0\n",
      "  (0, 50)\t-1.0\n",
      "  (0, 54)\t-1.0\n",
      "  (0, 57)\t-1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 79)\t-1.0\n",
      "  (0, 89)\t-2.0\n",
      "  (0, 96)\t-1.0\n",
      "  (6, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (16, 0)\t1.0\n",
      "  (21, 0)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (26, 0)\t1.0\n",
      "  (27, 0)\t1.0\n",
      "  (31, 0)\t1.0\n",
      "  (36, 0)\t1.0\n",
      "  (37, 0)\t1.0\n",
      "  (44, 0)\t1.0\n",
      "  (45, 0)\t1.0\n",
      "  (47, 0)\t-1.0\n",
      "  (51, 0)\t1.0\n",
      "  (54, 0)\t1.0\n",
      "  (59, 0)\t-1.0\n",
      "  (69, 0)\t1.0\n",
      "  (74, 0)\t1.0\n",
      "  (80, 0)\t1.0\n",
      "  (82, 0)\t1.0\n",
      "  (84, 0)\t1.0\n",
      "  (88, 0)\t1.0\n",
      "  (91, 0)\t1.0\n",
      "  (96, 0)\t1.0\n",
      "  (97, 0)\t1.0\n",
      "  :\t:\n",
      "  (7947, 0)\t-1.0\n",
      "  (7949, 0)\t1.0\n",
      "  (7957, 0)\t-1.0\n",
      "  (7958, 0)\t1.0\n",
      "  (7966, 0)\t1.0\n",
      "  (7968, 0)\t1.0\n",
      "  (7972, 0)\t2.0\n",
      "  (7973, 0)\t1.0\n",
      "  (7975, 0)\t1.0\n",
      "  (7976, 0)\t1.0\n",
      "  (7978, 0)\t1.0\n",
      "  (7981, 0)\t-1.0\n",
      "  (7991, 0)\t2.0\n",
      "  (7993, 0)\t1.0\n",
      "  (7995, 0)\t-1.0\n",
      "  (8000, 0)\t0.0\n",
      "  (8004, 0)\t1.0\n",
      "  (8021, 0)\t-1.0\n",
      "  (8023, 0)\t1.0\n",
      "  (8025, 0)\t0.0\n",
      "  (8034, 0)\t0.0\n",
      "  (8035, 0)\t1.0\n",
      "  (8051, 0)\t1.0\n",
      "  (8052, 0)\t-1.0\n",
      "  (8055, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_hash.shape)\n",
    "print(type(X_train_hash))\n",
    "print(X_train_hash[8000])\n",
    "print(X_train_hash[:,0])\n",
    "#print(X_train_hash.toarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.4396245695633043\n",
      "RF:  0.43471334823615365\n"
     ]
    }
   ],
   "source": [
    "l.fit(X_train_hash, y_train)\n",
    "y_pred = l.predict_proba(X_test_hash)\n",
    "print(\"LR: \", log_loss(y_test, y_pred))\n",
    "r.fit(X_train_hash,y_train)\n",
    "y_pred = r.predict_proba(X_test_hash)\n",
    "print(\"RF: \", log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Method 4: Encoding categories with dataset statistics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_df shape:  (9999, 21)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "X_train_count = copy.copy(X_train)\n",
    "X_test_count = copy.copy(X_test)\n",
    "X_train_count[\"test\"] = 0\n",
    "X_test_count[\"test\"] = 1\n",
    "temp_df = pandas.concat([X_train_count, X_test_count], axis=0)\n",
    "print(\"temp_df shape: \", temp_df.shape)\n",
    "for i in range(temp_df.shape[1]):\n",
    "    temp_df.iloc[:,i] = temp_df.iloc[:,i].astype('category')\n",
    "X_train_count = temp_df[temp_df[\"test\"]==0].iloc[:,:-1]\n",
    "X_test_count = temp_df[temp_df[\"test\"]==1].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1005\n",
      "1    1005\n",
      "2    1005\n",
      "3    1005\n",
      "4    1005\n",
      "Name: C1, dtype: category\n",
      "Categories (6, object): [1001, 1002, 1005, 1007, 1008, 1010]\n",
      "(8056, 20)\n",
      "1005    7459\n",
      "1002     301\n",
      "1010     281\n",
      "1007      10\n",
      "1001       3\n",
      "1008       2\n",
      "Name: C1, dtype: int64\n",
      "1001       3\n",
      "1002     301\n",
      "1005    7459\n",
      "1007      10\n",
      "1008       2\n",
      "1010     281\n",
      "Name: C1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = X_train_count.iloc[:,0].value_counts()\n",
    "print(X_train_count.iloc[0:5,0])\n",
    "print(X_train_count.shape)\n",
    "print(counts.head(30))\n",
    "print(counts.sort_index())\n",
    "counts = counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = counts.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72946933, 0.48975975, 0.85769324, 0.45669378, 0.33565994,\n",
       "       0.45931782])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.66973216e-05, 7.96347800e-04, 4.05204558e-04, 3.94163354e-04,\n",
       "       2.88750418e-04, 4.89610021e-04])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(len(counts)) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001       3.000593\n",
      "1002     301.000132\n",
      "1005    7459.000842\n",
      "1007      10.000260\n",
      "1008       2.000495\n",
      "1010     281.000607\n",
      "Name: C1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "counts = counts + np.random.rand(len(counts)) / 1000\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(X_train_count.shape[1]):\n",
    "    counts = X_train_count.iloc[:,i].value_counts()\n",
    "    counts = counts.sort_index()\n",
    "    counts = counts.fillna(0)\n",
    "    counts += np.random.rand(len(counts)) / 1000\n",
    "    X_train_count.iloc[:,i].cat.categories = counts\n",
    "    X_test_count.iloc[:,i].cat.categories = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([3.0009647617467285,  301.0005224054728, 7459.0001783582575,\n",
      "               10.00098079563379,  2.000195049512278, 281.00011922963637],\n",
      "             dtype='float64', name='C1')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_count.iloc[:,0].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.4477828125597004\n",
      "RF:  0.43341654731879725\n"
     ]
    }
   ],
   "source": [
    "l.fit(X_train_count, y_train)\n",
    "y_pred = l.predict_proba(X_test_count)\n",
    "print(\"LR: \", log_loss(y_test, y_pred))\n",
    "r.fit(X_train_count,y_train)\n",
    "y_pred = r.predict_proba(X_test_count)\n",
    "print(\"RF: \", \n",
    "      log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ctr = copy.copy(X_train)\n",
    "X_test_ctr = copy.copy(X_test)\n",
    "X_train_ctr[\"test\"]=0\n",
    "X_test_ctr[\"test\"]=1\n",
    "temp_df = pandas.concat([X_train_ctr,X_test_ctr],axis=0)\n",
    "for i in range(temp_df.shape[1]):\n",
    "    temp_df.iloc[:,i]=temp_df.iloc[:,i].astype('category')\n",
    "X_train_ctr=temp_df[temp_df[\"test\"]==0].iloc[:,:-1]\n",
    "X_test_ctr=temp_df[temp_df[\"test\"]==1].iloc[:,:-1]\n",
    "temp_df = pandas.concat([X_train_ctr,y_train],axis=1)\n",
    "names = list(X_train_ctr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category', 'device_id', 'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
      "(8056, 21)\n",
      "     C1 banner_pos   site_id site_domain site_category    app_id app_domain  \\\n",
      "0  1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
      "1  1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
      "\n",
      "  app_category device_id device_model  ...  device_conn_type    C14  C15 C16  \\\n",
      "0     07d7df22  a99f214a     44956a24  ...                 2  15706  320  50   \n",
      "1     07d7df22  a99f214a     711ee120  ...                 0  15704  320  50   \n",
      "\n",
      "    C17 C18 C19     C20 C21 click  \n",
      "0  1722   0  35      -1  79     0  \n",
      "1  1722   0  35  100084  79     0  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(names)\n",
    "print(temp_df.shape)\n",
    "print(temp_df.iloc[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1\n",
      "1001    0.000000\n",
      "1002    0.182724\n",
      "1005    0.171203\n",
      "1007    0.000000\n",
      "1008    1.000000\n",
      "1010    0.067616\n",
      "Name: click, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "means = temp_df.groupby('C1')['click'].mean()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1679493545183714"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(temp_df['click']) / len(temp_df['click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1\n",
      "1001    0.000000\n",
      "1002    0.182724\n",
      "1005    0.171203\n",
      "1007    0.000000\n",
      "1008    1.000000\n",
      "1010    0.067616\n",
      "Name: click, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "means = means.fillna(sum(temp_df['click'])/len(temp_df['click']))\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         C1 banner_pos   site_id site_domain site_category    app_id  \\\n",
      "0  0.171707   0.164319  0.202797    0.202926      0.202333  0.187886   \n",
      "1  0.171707   0.164319  0.202797    0.202926      0.202333  0.187886   \n",
      "2  0.171707   0.164319  0.202797    0.202926      0.202333  0.187886   \n",
      "\n",
      "  app_domain app_category device_id device_model device_type device_conn_type  \\\n",
      "0   0.182057     0.187599   0.17734     0.000260    0.171459         0.149092   \n",
      "1   0.182057     0.187599   0.17734     0.181202    0.171459         0.171467   \n",
      "2   0.182057     0.187599   0.17734     0.128727    0.171459         0.171467   \n",
      "\n",
      "        C14       C15       C16     C17       C18       C19       C20  \\\n",
      "0  0.132530  0.157847  0.158131  0.1955  0.152665  0.159945  0.172641   \n",
      "1  0.173228  0.157847  0.158131  0.1955  0.152665  0.159945  0.227386   \n",
      "2  0.173228  0.157847  0.158131  0.1955  0.152665  0.159945  0.227386   \n",
      "\n",
      "        C21  \n",
      "0  0.195305  \n",
      "1  0.195305  \n",
      "2  0.195305  \n"
     ]
    }
   ],
   "source": [
    "for i in names:\n",
    "    means = temp_df.groupby(i)['click'].mean()\n",
    "    means = means.fillna(sum(temp_df['click'])/len(temp_df['click']))\n",
    "    means += np.random.rand(len(means))/1000\n",
    "    X_train_ctr[i].cat.categories = means\n",
    "    X_test_ctr[i].cat.categories = means\n",
    "                  \n",
    "print(X_train_ctr.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.4700630472558881\n"
     ]
    }
   ],
   "source": [
    "l.fit(X_train_ctr,y_train)\n",
    "y_pred = l.predict_proba(X_test_ctr)\n",
    "print(\"LR: \", log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF:  0.45554757757739295\n"
     ]
    }
   ],
   "source": [
    "r.fit(X_train_ctr,y_train)\n",
    "y_pred = r.predict_proba(X_test_ctr)\n",
    "print(\"RF: \", log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Method 5: Cat2Vec</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "[['Feature C1 1005', 'Feature banner_pos 0', 'Feature site_id 1fbe01fe', 'Feature site_domain f3845767', 'Feature site_category 28905ebd', 'Feature app_id ecad2386', 'Feature app_domain 7801e8d9', 'Feature app_category 07d7df22', 'Feature device_id a99f214a', 'Feature device_model 44956a24', 'Feature device_type 1', 'Feature device_conn_type 2', 'Feature C14 15706', 'Feature C15 320', 'Feature C16 50', 'Feature C17 1722', 'Feature C18 0', 'Feature C19 35', 'Feature C20 -1', 'Feature C21 79']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from random import shuffle\n",
    "size=6\n",
    "window=8\n",
    "x_w2v = copy.deepcopy(train.iloc[:,features])\n",
    "names = list(x_w2v.columns.values)\n",
    "for i in names:\n",
    "    x_w2v[i]=x_w2v[i].astype('category')\n",
    "    x_w2v[i].cat.categories = [\"Feature %s %s\" % (i,g) for g in x_w2v[i].cat.categories]\n",
    "x_w2v = x_w2v.values.tolist()\n",
    "print(len(x_w2v))\n",
    "print(x_w2v[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Feature site_domain f3845767', 'Feature banner_pos 0', 'Feature device_model 44956a24', 'Feature device_type 1', 'Feature C20 -1', 'Feature device_id a99f214a', 'Feature device_conn_type 2', 'Feature C14 15706', 'Feature app_domain 7801e8d9', 'Feature app_category 07d7df22', 'Feature site_category 28905ebd', 'Feature site_id 1fbe01fe', 'Feature C15 320', 'Feature C19 35', 'Feature C1 1005', 'Feature C21 79', 'Feature app_id ecad2386', 'Feature C18 0', 'Feature C16 50', 'Feature C17 1722']]\n"
     ]
    }
   ],
   "source": [
    "for i in x_w2v:\n",
    "    shuffle(i) # shuffle columns per row\n",
    "print(x_w2v[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = Word2Vec(x_w2v,size=size,window=window) # create object, size means embedding dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_w2v = copy.copy(X_train)\n",
    "X_test_w2v = copy.copy(X_test)\n",
    "for i in names:\n",
    "    X_train_w2v[i]=X_train_w2v[i].astype('category')\n",
    "    X_train_w2v[i].cat.categories = [\"Feature %s %s\" % (i,g) for g in X_train_w2v[i].cat.categories]\n",
    "for i in names:\n",
    "    X_test_w2v[i]=X_test_w2v[i].astype('category')\n",
    "    X_test_w2v[i].cat.categories = [\"Feature %s %s\" % (i,g) for g in X_test_w2v[i].cat.categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                C1            banner_pos                   site_id  \\\n",
      "0  Feature C1 1005  Feature banner_pos 0  Feature site_id 1fbe01fe   \n",
      "\n",
      "                    site_domain                   site_category  \\\n",
      "0  Feature site_domain f3845767  Feature site_category 28905ebd   \n",
      "\n",
      "                    app_id                   app_domain  \\\n",
      "0  Feature app_id ecad2386  Feature app_domain 7801e8d9   \n",
      "\n",
      "                    app_category                   device_id  \\\n",
      "0  Feature app_category 07d7df22  Feature device_id a99f214a   \n",
      "\n",
      "                    device_model ...             device_conn_type  \\\n",
      "0  Feature device_model 44956a24 ...   Feature device_conn_type 2   \n",
      "\n",
      "                 C14              C15             C16               C17  \\\n",
      "0  Feature C14 15706  Feature C15 320  Feature C16 50  Feature C17 1722   \n",
      "\n",
      "             C18             C19             C20             C21 test  \n",
      "0  Feature C18 0  Feature C19 35  Feature C20 -1  Feature C21 79    0  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_w2v.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feature C1 1005' 'Feature banner_pos 0' 'Feature site_id 1fbe01fe'\n",
      " 'Feature site_domain f3845767' 'Feature site_category 28905ebd'\n",
      " 'Feature app_id ecad2386' 'Feature app_domain 7801e8d9'\n",
      " 'Feature app_category 07d7df22' 'Feature device_id a99f214a'\n",
      " 'Feature device_model 44956a24' 'Feature device_type 1'\n",
      " 'Feature device_conn_type 2' 'Feature C14 15706' 'Feature C15 320'\n",
      " 'Feature C16 50' 'Feature C17 1722' 'Feature C18 0' 'Feature C19 35'\n",
      " 'Feature C20 -1' 'Feature C21 79' 0]\n"
     ]
    }
   ],
   "source": [
    "X_train_w2v = X_train_w2v.values # One list having all columns per row\n",
    "X_test_w2v = X_test_w2v.values\n",
    "print(X_train_w2v[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n",
      "21\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_w2v))\n",
    "print(X_train_w2v.shape[1])\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8056, 126)\n",
      "<gensim.models.word2vec.Word2VecVocab object at 0x10dce0588>\n",
      "<class 'str'>\n",
      "xxx\n",
      "[-0.84423256  1.2427202  -0.26425478 -1.1727661   1.1989584  -0.8525728 ]\n"
     ]
    }
   ],
   "source": [
    "# initialize a size of 8011 * 126 \n",
    "# 6 embedding size * 21 columns = 126\n",
    "x_w2v_train = np.random.random((len(X_train_w2v),size*X_train_w2v.shape[1]))\n",
    "print(x_w2v_train.shape) \n",
    "print(w2v.vocabulary)\n",
    "#print(help(w2v))\n",
    "print(type(X_train_w2v[0,0]))\n",
    "if (w2v.wv.__contains__(\"Feature C1 1005\")):\n",
    "    print(\"xxx\")\n",
    "    print(w2v.wv.__getitem__(\"Feature C1 1005\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonsoomoon/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  app.launch_new_instance()\n",
      "/Users/gonsoomoon/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "for j in range(X_train_w2v.shape[1]):\n",
    "    for i in range(X_train_w2v.shape[0]):\n",
    "        if X_train_w2v[i,j] in w2v:\n",
    "            x_w2v_train[i,j*size:(j+1)*size] = w2v[X_train_w2v[i,j]]\n",
    "            #print(w2v[X_train_w2v[i,j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonsoomoon/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/Users/gonsoomoon/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "x_w2v_test = np.random.random((len(X_test_w2v),size*X_test_w2v.shape[1]))\n",
    "for j in range(X_test_w2v.shape[1]):\n",
    "    for i in range(X_test_w2v.shape[0]):\n",
    "        if X_test_w2v[i,j] in w2v:\n",
    "            x_w2v_test[i,j*size:(j+1)*size] = w2v[X_test_w2v[i,j]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.4330431221683492\n",
      "RF:  0.4320668190285643\n"
     ]
    }
   ],
   "source": [
    "l.fit(x_w2v_train,y_train)\n",
    "y_pred = l.predict_proba(x_w2v_test)\n",
    "print(\"LR: \", log_loss(y_test,y_pred))\n",
    "r.fit(x_w2v_train,y_train)\n",
    "y_pred = r.predict_proba(x_w2v_test)\n",
    "print(\"RF: \", log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Method 6: Category embedding with deep learning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8056, 20) (1943, 20)\n",
      "[1005 0 '1fbe01fe' 'f3845767' '28905ebd' 'ecad2386' '7801e8d9' '07d7df22'\n",
      " 'a99f214a' '44956a24' 1 2 15706 320 50 1722 0 35 -1 79]\n",
      "     C1  banner_pos   site_id site_domain site_category    app_id app_domain  \\\n",
      "0  1005           0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
      "\n",
      "  app_category device_id device_model  device_type  device_conn_type    C14  \\\n",
      "0     07d7df22  a99f214a     44956a24            1                 2  15706   \n",
      "\n",
      "   C15  C16   C17  C18  C19  C20  C21  \n",
      "0  320   50  1722    0   35   -1   79  \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Reshape\n",
    "from keras.layers import Merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "X_train_dnn = copy.copy(X_train_ori).values\n",
    "X_test_dnn = copy.copy(X_test_ori).values\n",
    "print(X_train_dnn.shape, X_test_dnn.shape)\n",
    "print(X_train_dnn[0,:])\n",
    "print(X_train_ori.head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8056, 20) (1943, 20)\n",
      "[[2 0 43 301 2 293 13 0 722 315 1 1 67 2 1 27 0 0 0 15]\n",
      " [2 0 43 301 2 293 13 0 722 488 1 0 65 2 1 27 0 0 42 15]]\n"
     ]
    }
   ],
   "source": [
    "les = []\n",
    "for i in range(X_train_dnn.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train.iloc[:,features].iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_dnn[:, i] = le.transform(X_train_dnn[:, i])\n",
    "    X_test_dnn[:, i] = le.transform(X_test_dnn[:, i])\n",
    "print(X_train_dnn.shape, X_test_dnn.shape)\n",
    "print(X_train_dnn[0:2,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "[[2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "X = X_train_dnn\n",
    "print(X[...,[0]])\n",
    "print(X[0:3,[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_features(X):\n",
    "    X_list = []\n",
    "    \n",
    "    C1 = X[..., [0]]\n",
    "    X_list.append(C1)\n",
    "    banner_pos = X[..., [1]]\n",
    "    X_list.append(banner_pos)\n",
    "    site_id = X[..., [2]]\n",
    "    X_list.append(site_id)\n",
    "    \n",
    "    site_domain = X[..., [3]]\n",
    "    X_list.append(site_domain)\n",
    "    site_category = X[..., [4]]\n",
    "    X_list.append(site_category)\n",
    "    app_id = X[..., [5]]\n",
    "    X_list.append(app_id)\n",
    "    app_domain = X[..., [6]]\n",
    "    X_list.append(app_domain)\n",
    "    app_category = X[..., [7]]\n",
    "    X_list.append(app_category)\n",
    "    \n",
    "    device_id = X[..., [8]]\n",
    "    X_list.append(device_id)\n",
    "    device_model = X[..., [9]]\n",
    "    X_list.append(device_model)\n",
    "    device_type = X[..., [10]]\n",
    "    X_list.append(device_type)\n",
    "    \n",
    "    device_conn_type = X[..., [11]]\n",
    "    X_list.append(device_conn_type)\n",
    "    C14 = X[..., [12]]\n",
    "    X_list.append(C14)\n",
    "    \n",
    "    C15 = X[..., [13]]\n",
    "    X_list.append(C15)\n",
    "    C16 = X[..., [14]]\n",
    "    X_list.append(C16)\n",
    "    C17 = X[..., [15]]\n",
    "    X_list.append(C17)\n",
    "    C18 = X[..., [16]]\n",
    "    X_list.append(C18)\n",
    "    C19 = X[..., [17]]\n",
    "    X_list.append(C19)\n",
    "    \n",
    "    C20 = X[..., [18]]\n",
    "    X_list.append(C20)\n",
    "    C21 = X[..., [19]]\n",
    "    X_list.append(C21)\n",
    "    \n",
    "    return X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NN_with_EntityEmbedding(object):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.nb_epoch = 1\n",
    "        self.__build_keras_model()\n",
    "        self.fit(X_train, y_train, X_val, y_val)\n",
    "    def preprocessing(self, X):\n",
    "        X_list = split_features(X)\n",
    "        print(\"X shape: \", np.array(X).shape)\n",
    "        print(\"X_list shape: \", np.array(X_list).shape)        \n",
    "        return X_list\n",
    "    def __build_keras_model(self):\n",
    "        models = []\n",
    "        \n",
    "        model_C1 = Sequential()\n",
    "        model_C1.add(Embedding(len(les[0].classes_), 3, input_length=1)) # Turns positive integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]\n",
    "        model_C1.add(Reshape(target_shape=(3,)))\n",
    "        models.append(model_C1)\n",
    "        print(\"Label Encoder Size: \", len(les[0].classes_))\n",
    "        \n",
    "        model_banner_pos = Sequential()\n",
    "        model_banner_pos.add(Embedding(len(les[1].classes_), 3, input_length=1))\n",
    "        model_banner_pos.add(Reshape(target_shape=(3,)))\n",
    "        models.append(model_banner_pos)\n",
    "        print(\"Label Encoder Size: \", len(les[1].classes_))\n",
    "            \n",
    "        model_site_id = Sequential()\n",
    "        model_site_id.add(Embedding(len(les[2].classes_), 8, input_length=1))\n",
    "        model_site_id.add(Reshape(target_shape=(8,)))\n",
    "        models.append(model_site_id)\n",
    "        print(\"Label Encoder Size: \", len(les[2].classes_))        \n",
    "        \n",
    "        site_domain = Sequential()\n",
    "        site_domain.add(Embedding(len(les[3].classes_), 8, input_length=1))\n",
    "        site_domain.add(Reshape(target_shape=(8,)))\n",
    "        models.append(site_domain)\n",
    "        site_category = Sequential()\n",
    "        site_category.add(Embedding(len(les[4].classes_), 3, input_length=1))\n",
    "        site_category.add(Reshape(target_shape=(3,)))\n",
    "        models.append(site_category)\n",
    "        app_id = Sequential()\n",
    "        app_id.add(Embedding(len(les[5].classes_), 8, input_length=1))\n",
    "        app_id.add(Reshape(target_shape=(8,)))\n",
    "        models.append(app_id)\n",
    "        app_domain = Sequential()\n",
    "        app_domain.add(Embedding(len(les[6].classes_), 4, input_length=1))\n",
    "        app_domain.add(Reshape(target_shape=(4,)))\n",
    "        models.append(app_domain)\n",
    "        \n",
    "        app_category = Sequential()\n",
    "        app_category.add(Embedding(len(les[7].classes_), 3, input_length=1))\n",
    "        app_category.add(Reshape(target_shape=(3,)))\n",
    "        models.append(app_category)\n",
    "        \n",
    "        device_id = Sequential()\n",
    "        device_id.add(Embedding(len(les[8].classes_), 10, input_length=1))\n",
    "        device_id.add(Reshape(target_shape=(10,)))\n",
    "        models.append(device_id)\n",
    "        \n",
    "        device_model = Sequential()\n",
    "        device_model.add(Embedding(len(les[9].classes_), 8, input_length=1))\n",
    "        device_model.add(Reshape(target_shape=(8,)))\n",
    "        models.append(device_model)\n",
    "        \n",
    "        device_type = Sequential()\n",
    "        device_type.add(Embedding(len(les[10].classes_), 2, input_length=1))\n",
    "        device_type.add(Reshape(target_shape=(2,)))\n",
    "        models.append(device_type)\n",
    "        \n",
    "        device_conn_type = Sequential()\n",
    "        device_conn_type.add(Embedding(len(les[11].classes_), 2, input_length=1))\n",
    "        device_conn_type.add(Reshape(target_shape=(2,)))\n",
    "        models.append(device_conn_type)\n",
    "        \n",
    "        C14 = Sequential()\n",
    "        C14.add(Embedding(len(les[12].classes_), 8, input_length=1))\n",
    "        C14.add(Reshape(target_shape=(8,)))\n",
    "        models.append(C14)\n",
    "        \n",
    "        C15 = Sequential()\n",
    "        C15.add(Embedding(len(les[13].classes_), 3, input_length=1))\n",
    "        C15.add(Reshape(target_shape=(3,)))\n",
    "        models.append(C15)\n",
    "        \n",
    "        C16 = Sequential()\n",
    "        C16.add(Embedding(len(les[14].classes_), 3, input_length=1))\n",
    "        C16.add(Reshape(target_shape=(3,)))\n",
    "        models.append(C16)\n",
    "        \n",
    "        C17 = Sequential()\n",
    "        C17.add(Embedding(len(les[15].classes_), 4, input_length=1))\n",
    "        C17.add(Reshape(target_shape=(4,)))\n",
    "        models.append(C17)\n",
    "        \n",
    "        C18 = Sequential()\n",
    "        C18.add(Embedding(len(les[16].classes_), 2, input_length=1))\n",
    "        C18.add(Reshape(target_shape=(2,)))\n",
    "        models.append(C18)\n",
    "        \n",
    "        C19 = Sequential()\n",
    "        C19.add(Embedding(len(les[17].classes_), 4, input_length=1))\n",
    "        C19.add(Reshape(target_shape=(4,)))\n",
    "        models.append(C19)\n",
    "        \n",
    "        C20 = Sequential()\n",
    "        C20.add(Embedding(len(les[18].classes_), 5, input_length=1))\n",
    "        C20.add(Reshape(target_shape=(5,)))\n",
    "        models.append(C20)\n",
    "        \n",
    "        C21 = Sequential()\n",
    "        C21.add(Embedding(len(les[19].classes_), 4, input_length=1))\n",
    "        C21.add(Reshape(target_shape=(4,)))\n",
    "        models.append(C21)\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Merge(models, mode = 'concat'))\n",
    "        self.model.add(Dense(150, kernel_initializer='uniform'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(250, kernel_initializer='uniform'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.add(Activation('sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        X_pre_train = self.preprocessing(X_train)\n",
    "        print(\"X_pre_train shape: \", np.array(X_pre_train).shape)\n",
    "        X_pre_val = self.preprocessing(X_val)   \n",
    "        print(\"X_pre_val shape: \", np.array(X_pre_val).shape)        \n",
    "        print(\"y_train shape: \", np.array(y_train).shape)        \n",
    "        print(\"y_val shape: \", np.array(y_val).shape)        \n",
    "        \n",
    "        \n",
    "        self.model.fit(X_pre_train, y_train,\n",
    "                      validation_data=(X_pre_val, y_val),\n",
    "                      epochs=self.nb_epoch, batch_size=128,)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder Size:  6\n",
      "Label Encoder Size:  4\n",
      "Label Encoder Size:  381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonsoomoon/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:117: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (8056, 20)\n",
      "X_list shape:  (20, 8056, 1)\n",
      "X_pre_train shape:  (20, 8056, 1)\n",
      "X shape:  (1943, 20)\n",
      "X_list shape:  (20, 1943, 1)\n",
      "X_pre_val shape:  (20, 1943, 1)\n",
      "y_train shape:  (8056,)\n",
      "y_val shape:  (1943,)\n",
      "Train on 8056 samples, validate on 1943 samples\n",
      "Epoch 1/1\n",
      "8056/8056 [==============================] - 3s 413us/step - loss: 0.4822 - acc: 0.8282 - val_loss: 0.4400 - val_acc: 0.8183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_19 (Merge)             (None, 95)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 150)               14400     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 250)               37750     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 84,268\n",
      "Trainable params: 84,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn = NN_with_EntityEmbedding(X_train_dnn, y_train, X_test_dnn, y_test)\n",
    "weights = dnn.model.get_weights()\n",
    "n=0\n",
    "\n",
    "dnn.model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,40,2):\n",
    "    n = n + (weights[i][0].shape)[1]\n",
    "    \n",
    "x_dnn_train = np.random.random((len(X_train_dnn), n))\n",
    "start_ind = 0\n",
    "for j in range(X_train_dnn.shape[1]):\n",
    "    mat = weights[j*2][0]\n",
    "    dim = mat.shape[1]\n",
    "    for i in range(X_train_dnn.shape[0]):\n",
    "        x_dnn_train[i, start_ind:start_ind + dim] = mat[X_train_dnn[i,j]]\n",
    "    start_ind += dim\n",
    "x_dnn_test = np.random.random((len(X_test_dnn),n))\n",
    "start_ind = 0\n",
    "for j in range(X_test_dnn.shape[1]):\n",
    "    mat = weights[j*2][0]\n",
    "    dim = mat.shape[1]\n",
    "    for i in range(x_dnn_test.shape[0]):\n",
    "        x_dnn_test[i,start_ind:start_ind+dim]=mat[X_test_dnn[i,j]]\n",
    "    start_ind += dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4753951686013886\n",
      "0.4717856780089146\n"
     ]
    }
   ],
   "source": [
    "l.fit(x_dnn_train,y_train)\n",
    "y_pred = l.predict_proba(x_dnn_test)\n",
    "print(log_loss(y_test,y_pred))\n",
    "r.fit(x_dnn_train,y_train)\n",
    "y_pred = r.predict_proba(x_dnn_test)\n",
    "print(log_loss(y_test,y_pred))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "def split_features(X):\n",
    "    X_list = []\n",
    "C1 = X[..., [0]]\n",
    "    X_list.append(C1)\n",
    "banner_pos = X[..., [1]]\n",
    "    X_list.append(banner_pos)\n",
    "site_id = X[..., [2]]\n",
    "    X_list.append(site_id)\n",
    "    \n",
    "    site_domain = X[..., [3]]\n",
    "    X_list.append(site_domain)\n",
    "site_category = X[..., [4]]\n",
    "    X_list.append(site_category)\n",
    "app_id = X[..., [5]]\n",
    "    X_list.append(app_id)\n",
    "app_domain = X[..., [6]]\n",
    "    X_list.append(app_domain)\n",
    "app_category = X[..., [7]]\n",
    "    X_list.append(app_category)\n",
    "    \n",
    "    device_id = X[..., [8]]\n",
    "    X_list.append(device_id)\n",
    "device_model = X[..., [9]]\n",
    "    X_list.append(device_model)\n",
    "device_type = X[..., [10]]\n",
    "    X_list.append(device_type)\n",
    "    \n",
    "    device_conn_type = X[..., [11]]\n",
    "    X_list.append(device_conn_type)\n",
    "C14 = X[..., [12]]\n",
    "    X_list.append(C14)\n",
    "    \n",
    "    C15 = X[..., [13]]\n",
    "    X_list.append(C15)\n",
    "C16 = X[..., [14]]\n",
    "    X_list.append(C16)\n",
    "C17 = X[..., [15]]\n",
    "    X_list.append(C17)\n",
    "C18 = X[..., [16]]\n",
    "    X_list.append(C18)\n",
    "C19 = X[..., [17]]\n",
    "    X_list.append(C19)\n",
    "    \n",
    "    C20 = X[..., [18]]\n",
    "    X_list.append(C20)\n",
    "C21 = X[..., [19]]\n",
    "    X_list.append(C21)\n",
    "return X_list\n",
    "\n",
    "class NN_with_EntityEmbedding(object):\n",
    "def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.nb_epoch = 10\n",
    "        self.__build_keras_model()\n",
    "        self.fit(X_train, y_train, X_val, y_val)\n",
    "def preprocessing(self, X):\n",
    "        X_list = split_features(X)\n",
    "        return X_list\n",
    "def __build_keras_model(self):\n",
    "        models = []\n",
    "        model_C1= Sequential()\n",
    "        model_C1.add(Embedding(len(les[0].classes_), 3, input_length=1))\n",
    "        model_C1.add(Reshape(target_shape=(3,)))\n",
    "        models.append(model_C1)\n",
    "        \n",
    "        model_banner_pos = Sequential()\n",
    "        model_banner_pos.add(Embedding(len(les[1].classes_), 3, input_length=1))\n",
    "        model_banner_pos.add(Reshape(target_shape=(3,)))\n",
    "        models.append(model_banner_pos)\n",
    "        \n",
    "        model_site_id = Sequential()\n",
    "        model_site_id.add(Embedding(len(les[2].classes_), 8, input_length=1))\n",
    "        model_site_id.add(Reshape(target_shape=(8,)))\n",
    "        models.append(model_site_id)\n",
    "        \n",
    "        site_domain = Sequential()\n",
    "        site_domain.add(Embedding(len(les[3].classes_), 8, input_length=1))\n",
    "        site_domain.add(Reshape(target_shape=(8,)))\n",
    "        models.append(site_domain)\n",
    "site_category = Sequential()\n",
    "        site_category.add(Embedding(len(les[4].classes_), 3, input_length=1))\n",
    "        site_category.add(Reshape(target_shape=(3,)))\n",
    "        models.append(site_category)\n",
    "app_id = Sequential()\n",
    "        app_id.add(Embedding(len(les[5].classes_), 8, input_length=1))\n",
    "        app_id.add(Reshape(target_shape=(8,)))\n",
    "        models.append(app_id)\n",
    "app_domain = Sequential()\n",
    "        app_domain.add(Embedding(len(les[6].classes_), 4, input_length=1))\n",
    "        app_domain.add(Reshape(target_shape=(4,)))\n",
    "        models.append(app_domain)\n",
    "        \n",
    "        app_category = Sequential()\n",
    "        app_category.add(Embedding(len(les[7].classes_), 3, input_length=1))\n",
    "        app_category.add(Reshape(target_shape=(3,)))\n",
    "        models.append(app_category)\n",
    "        \n",
    "        device_id = Sequential()\n",
    "        device_id.add(Embedding(len(les[8].classes_), 10, input_length=1))\n",
    "        device_id.add(Reshape(target_shape=(10,)))\n",
    "        models.append(device_id)\n",
    "        \n",
    "        device_model = Sequential()\n",
    "        device_model.add(Embedding(len(les[9].classes_), 8, input_length=1))\n",
    "        device_model.add(Reshape(target_shape=(8,)))\n",
    "        models.append(device_model)\n",
    "        \n",
    "        device_type = Sequential()\n",
    "        device_type.add(Embedding(len(les[10].classes_), 2, input_length=1))\n",
    "        device_type.add(Reshape(target_shape=(2,)))\n",
    "        models.append(device_type)\n",
    "        \n",
    "        device_conn_type = Sequential()\n",
    "        device_conn_type.add(Embedding(len(les[11].classes_), 2, input_length=1))\n",
    "        device_conn_type.add(Reshape(target_shape=(2,)))\n",
    "        models.append(device_conn_type)\n",
    "C14 = Sequential()\n",
    "        C14.add(Embedding(len(les[12].classes_), 8, input_length=1))\n",
    "        C14.add(Reshape(target_shape=(8,)))\n",
    "        models.append(C14)\n",
    "        \n",
    "        C15 = Sequential()\n",
    "        C15.add(Embedding(len(les[13].classes_), 3, input_length=1))\n",
    "        C15.add(Reshape(target_shape=(3,)))\n",
    "        models.append(C15)\n",
    "        \n",
    "        C16 = Sequential()\n",
    "        C16.add(Embedding(len(les[14].classes_), 3, input_length=1))\n",
    "        C16.add(Reshape(target_shape=(3,)))\n",
    "        models.append(C16)\n",
    "        \n",
    "        C17 = Sequential()\n",
    "        C17.add(Embedding(len(les[15].classes_), 4, input_length=1))\n",
    "        C17.add(Reshape(target_shape=(4,)))\n",
    "        models.append(C17)\n",
    "        \n",
    "        C18 = Sequential()\n",
    "        C18.add(Embedding(len(les[16].classes_), 2, input_length=1))\n",
    "        C18.add(Reshape(target_shape=(2,)))\n",
    "        models.append(C18)\n",
    "        \n",
    "        C19 = Sequential()\n",
    "        C19.add(Embedding(len(les[17].classes_), 4, input_length=1))\n",
    "        C19.add(Reshape(target_shape=(4,)))\n",
    "        models.append(C19)\n",
    "        \n",
    "        C20 = Sequential()\n",
    "        C20.add(Embedding(len(les[18].classes_), 5, input_length=1))\n",
    "        C20.add(Reshape(target_shape=(5,)))\n",
    "        models.append(C20)\n",
    "        \n",
    "        C21 = Sequential()\n",
    "        C21.add(Embedding(len(les[19].classes_), 4, input_length=1))\n",
    "        C21.add(Reshape(target_shape=(4,)))\n",
    "        models.append(C21)\n",
    "self.model = Sequential()\n",
    "        self.model.add(Merge(models, mode='concat'))\n",
    "        self.model.add(Dense(150, kernel_initializer='uniform'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(250, kernel_initializer='uniform'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.add(Activation('sigmoid'))\n",
    "self.model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "             metrics=['acc'])\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        self.model.fit(self.preprocessing(X_train), y_train,\n",
    "                       validation_data=(self.preprocessing(X_val), y_val),\n",
    "                       epochs=self.nb_epoch, batch_size=128,\n",
    "                       )\n",
    "dnn = NN_with_EntityEmbedding(X_train_dnn, y_train, X_test_dnn, y_test)   \n",
    "weights = dnn.model.get_weights()\n",
    "n = 0\n",
    "for i in range(0,40,2):\n",
    "    n+=(weights[i][0].shape)[1]\n",
    "    \n",
    "x_dnn_train = np.random.random((len(X_train_dnn),n))\n",
    "start_ind=0\n",
    "for j in range(X_train_dnn.shape[1]):\n",
    "    mat = weights[j*2][0]\n",
    "    dim = mat.shape[1]\n",
    "    for i in range(X_train_dnn.shape[0]):\n",
    "        x_dnn_train[i,start_ind:start_ind+dim]=mat[X_train_dnn[i,j]]\n",
    "    start_ind += dim\n",
    "x_dnn_test = np.random.random((len(X_test_dnn),n))\n",
    "start_ind=0\n",
    "for j in range(X_test_dnn.shape[1]):\n",
    "    mat = weights[j*2][0]\n",
    "    dim = mat.shape[1]\n",
    "    for i in range(x_dnn_test.shape[0]):\n",
    "        x_dnn_test[i,start_ind:start_ind+dim]=mat[X_test_dnn[i,j]]\n",
    "    start_ind += dim\n",
    "l.fit(x_dnn_train,y_train)\n",
    "y_pred = l.predict_proba(x_dnn_test)\n",
    "print(log_loss(y_test,y_pred))\n",
    "r.fit(x_dnn_train,y_train)\n",
    "y_pred = r.predict_proba(x_dnn_test)\n",
    "print(log_loss(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
